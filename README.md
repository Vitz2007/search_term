# search_term

# Search Terms (2016~present)


#### -- Project Status: [Completed]


## Project Intro/Objective
The purpose of this project is to understand which words were searched over the last five years and predict which words would be searched next using Random Forest.


### Methods Used
* Inferential Statistics
* Machine Learning
* Data Visualization
* Predictive Modeling
* etc.


### Technologies
* Jupyter
* Python
* Pandas
* Numpy
* Matplot
* NLP (Natural language processing)
* NLTK (Natural language toolkit)
* Scikit Learn (Forest Regression, RandomizedSearchCV)


## Project Description
Search term data was obtained from [Zenodo](https://zenodo.org/record/3715353#.YNwCnWQzbzc) because it had the most recent data leading up to January 2020. Having interned as a digital marketer for a small consulting firm in Fukuoka, I was curious how users utilized the search engine for search from when my internship finished to 2020.
A challenge I faced cleaning the search term data was the punctuation marks. Removing them from the words column and making sure each year frequency matched with the right row made things interesting. But in the end I was able to extract punctuation marks and set them aside for further analysis (if need be).


## Needs of this project
- data exploration/descriptive statistics
- data processing/cleaning
- predictive modeling
- metrics


## Getting Started
- nltk library + nltk.download('stopwords') -- for filtering
